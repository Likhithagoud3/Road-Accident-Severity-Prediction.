# -*- coding: utf-8 -*-
"""Road Accident

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZYHXEPDkctblZIydSNZ9LRrSk41SFrks

## **EDA**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings as wr
wr.filterwarnings('ignore')

df=pd.read_csv('/content/road_accidents.csv')

df

df.head()

df.tail()

df.shape

df.columns

df.dtypes

#missing values
df.isnull().sum()

df = df.dropna()

df.isnull().sum()

X = df.drop("Accident_severity", axis=1)
y = df["Accident_severity"].astype(int)

plt.figure(figsize=(12,5))
sns.countplot(data=df, x='Weather_conditions', hue='Accident_severity')
plt.xticks(rotation=45)
plt.title("Severity vs Weather Conditions")
plt.show()

# Severity vs Light Conditions
# -------------------------
plt.figure(figsize=(12,5))
sns.countplot(data=df, x='Light_conditions', hue='Accident_severity')
plt.xticks(rotation=45)
plt.title("Severity vs Light Conditions")
plt.show()

# Severity vs Type of Vehicle
# -------------------------
plt.figure(figsize=(12,5))
sns.countplot(data=df, x='Type_of_vehicle', hue='Accident_severity')
plt.xticks(rotation=45)
plt.title("Severity vs Vehicle Type")
plt.show()

"""# pie"""

# Pie Chart - Severity Distribution
# -------------------------
severity_counts = df['Accident_severity'].value_counts()

plt.figure(figsize=(10,6))
plt.pie(severity_counts, labels=severity_counts.index, autopct='%1.1f%%', startangle=90)
plt.title("Accident Severity Distribution")
plt.axis('equal')
plt.show()

"""# correlation"""

# Correlation Heatmap (Numerical Columns)
# -------------------------
plt.figure(figsize=(10,6))
sns.heatmap(df.select_dtypes(include=['number']).corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

"""# histplot"""

# Histograms
# -------------------------
df.select_dtypes(include=['number']).hist(bins=10, figsize=(15, 10))
plt.show()

"""# Boxplot"""

# Boxplot for Outlier Detection
# -------------------------
plt.figure(figsize=(10, 6))
sns.boxplot(data=df.select_dtypes(include=['number']))
plt.title("Boxplot of Numerical Columns")
plt.xticks(rotation=45)
plt.show()

"""# DISTPLOT"""

sns.histplot(df['Number_of_vehicles_involved'])
plt.show()

"""# seaborn"""

sns.pairplot(df)
plt.show()

"""# Outlier Analysis"""

plt.figure(figsize=(10, 6))
sns.boxplot(data=df.select_dtypes(include=['number']))
plt.title("Boxplot of Numerical Columns for Outlier Analysis")
plt.xticks(rotation=45)
plt.show()

"""# Data preprocessing"""

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

for col in df.columns:
  df.loc[:, col] = le.fit_transform(df[col])

from sklearn.model_selection import train_test_split

X = df.drop('Accident_severity', axis=1)   # Features
y = df['Accident_severity']               # Target

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

"""# Model building"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

rf = RandomForestClassifier(n_estimators=200, random_state=42)
rf.fit(X_train, y_train.astype(int))

y_pred_rf = rf.predict(X_test)

print("Random Forest Accuracy:", accuracy_score(y_test.astype(int), y_pred_rf))
print("\nClassification Report:\n", classification_report(y_test.astype(int), y_pred_rf))
print("\nConfusion Matrix:\n", confusion_matrix(y_test.astype(int), y_pred_rf))

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train.astype(int))

y_pred_dt = dt.predict(X_test)

print("Decision Tree Accuracy:", accuracy_score(y_test.astype(int), y_pred_dt))

from sklearn.linear_model import LogisticRegression

log = LogisticRegression(max_iter=2000)
log.fit(X_train, y_train.astype(int))

y_pred_log = log.predict(X_test)

print("Logistic Regression Accuracy:", accuracy_score(y_test.astype(int), y_pred_log))

from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 1: Separate X and y
X = df.drop('Accident_severity', axis=1)
y = df['Accident_severity'].astype(int)  # Explicitly cast y to integer type

# Step 2: Apply SMOTE
sm = SMOTE(random_state=42)
X_resampled, y_resampled = sm.fit_resample(X, y)

# Step 3: Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_resampled, y_resampled, test_size=0.2, random_state=42
)

# Step 4: Train Random Forest
rf = RandomForestClassifier(n_estimators=200, random_state=42)
rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)

# Step 5: Results
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

target_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
print(target_mapping)

"""# Model Evaluation"""

print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.show()

importances = rf.feature_importances_
feat_importance = pd.Series(importances, index=X.columns).sort_values(ascending=False)
sns.barplot(x=feat_importance, y=feat_importance.index)
plt.title("Feature Importance")
plt.show()

import pickle

with open("accident_severity_model.pkl", "wb") as file:
    pickle.dump(rf, file)

print("âœ… Model saved successfully as accident_severity_model.pkl")